---
title: "Project 2"
author: Group 11
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: default
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  eval: true
  warning: false
  message: false
editor: 
  markdown: 
    wrap: sentence
---

```{r}
#| echo: true
library(tidyverse)
library(moderndive)
library(gapminder)
library(sjPlot)
library(stats)
library(jtools)
library(caret)
library(pROC)
library(MASS)
```

```{r}
#| echo: true
data<-read.csv("dataset11.csv")
data<-na.omit(data)
data<-data[data$altitude_mean_meters<100000,]
write.csv(data,"data.csv",row.names=FALSE)
summary(data$altitude_mean_meters)
data$Qualityclass_dummy<-ifelse(data$Qualityclass=="Poor",1,0) #for "Poor"=1 "Good"=0
data$Qualityclass <- as.factor(data$Qualityclass)
data$harvested <- as.factor(data$harvested)
```

#### We realized that the altitude_mean_meters have two outliers and it higher than the most highest altitude in the world, so we remove the outliers to make the data more reasonable.

```{r}
#| echo: true
library(tidyr)
data_long <- data %>%
  pivot_longer(cols = c(aroma,flavor,acidity,category_two_defects,altitude_mean_meters),
               names_to = "Variable",
               values_to = "Value")
library(ggplot2)
ggplot(data = data_long, aes(x = Qualityclass, y = Value, fill = Qualityclass)) +
  geom_boxplot() +
  facet_wrap(~Variable, scales = "free_y") +  
  theme_minimal() +
  labs(title = "Boxplots of 5 variables by quality",
       x = "qualityclass",
       y = "Value") +
  theme(legend.position = "none")
ggplot(data, aes(x=Qualityclass ,  y =..prop.., group=harvested, fill=harvested)) + 
  geom_bar(position="dodge", stat="count") +
  labs(y = "Proportion")
ggplot(data, aes(x=harvested ,  y = ..prop.., group=Qualityclass, fill=Qualityclass)) + 
  geom_bar(position="dodge", stat="count") +
  labs(y = "Proportion")
```

```{r}
#| echo: true
model1<- glm(Qualityclass_dummy ~ country_of_origin+aroma+flavor+acidity+category_two_defects+altitude_mean_meters+harvested, data = data, family = binomial(link = "logit"))
summary(model1)
summ(model1)
model2 <- glm(Qualityclass_dummy ~ aroma+flavor+acidity+category_two_defects+altitude_mean_meters+harvested, data = data, family = binomial(link = "logit"))
summary(model2)
summ(model2)
model3<-glm(Qualityclass_dummy~aroma+flavor+acidity+category_two_defects+altitude_mean_meters,data=data,family=binomial(link="logit"))
summary(model3)
summ(model3)
model4<-glm(Qualityclass_dummy~aroma+flavor+acidity+altitude_mean_meters,data=data,family=binomial(link="logit"))
summary(model4)
summ(model4)
model5<-glm(Qualityclass_dummy~aroma+flavor+acidity+category_two_defects,data=data,family=binomial(link="logit"))
summary(model5)
summ(model5)
model6<-glm(Qualityclass_dummy~aroma+flavor+acidity,data=data,family=binomial(link="logit"))
summary(model6)
summ(model6)
```

#### It shows that model 1,2,3,5 should be removed, and we could find that the altitude_mean_meters was significant in model 4, the p-value was 0.0455. So we should consider which model we choose between model 4 and model 6.

```{r}
#| echo: true
library(broom)
library(knitr)
Models<-c('model1','model2','model3','model4','model5','model6')
model.comp.values.model1<-glance(model1)
kable(model.comp.values.model1,digits=2)
model.comp.values.model2<-glance(model2)
kable(model.comp.values.model2,digits=2)
model.comp.values.model3<-glance(model3)
kable(model.comp.values.model3,digits=2)
model.comp.values.model4<-glance(model4)
kable(model.comp.values.model4,digits=2)
model.comp.values.model5<-glance(model5)
kable(model.comp.values.model5,digits=2)
model.comp.values.model6<-glance(model6)
kable(model.comp.values.model6,digits=2)


```

```{r}
#| echo: true
library(dplyr)
library(knitr)
library(jtools)
model_table <- bind_rows(
  data.frame(Model = "model1", AIC = AIC(model1, k = 2), BIC = BIC(model1)),
  data.frame(Model = "model2", AIC = AIC(model2, k = 2), BIC = BIC(model2)),
  data.frame(Model = "model3", AIC = AIC(model3, k = 2), BIC = BIC(model3)),
  data.frame(Model = "model4", AIC = AIC(model4, k = 2), BIC = BIC(model4)),
  data.frame(Model = "model5", AIC = AIC(model5, k = 2), BIC = BIC(model5)),
  data.frame(Model = "model6", AIC = AIC(model6, k = 2), BIC = BIC(model6))
)

kable(model_table, digits = 2, caption = "Comparison for the 6 models")
```

#### Above all of six models, we finally choose the model6 for our research, it was the most appropriate model for this research.

```{r}
#| echo: true
mod.coef.logodds<-model6 %>%
  summary() %>%
  coef()
plot_model(model6, show.values = TRUE, transform = NULL,
           title = "Log-Odds (quality-bad)", show.p = FALSE)
data<- data%>%
  mutate(logodds.bad = predict(model6))
model6 %>%
  coef() %>%
  exp()
exp(coef(model6))
plot_model(model6, show.values = TRUE, axis.lim = c(10,1000),
           title = "Odds (quality-bad)", show.p = FALSE)
data<- data%>%
  mutate(odds.bad = exp(logodds.bad))
data<- data%>%
  mutate(prob.bad = fitted(model6))
data_long1 <- data %>%
  pivot_longer(cols = c(aroma, flavor,acidity), names_to = "Type", values_to = "Value")
ggplot(data = data_long1, aes(x =Value, y =prob.bad, color = Type)) +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "score", y = "Probability of quality being bad", color = "character Type") +
  theme_minimal()
par(mfrow=c(1,3))  # 设置 1 行 3 列的画布
plot_model(model6, type = "pred", terms = "aroma", 
           title = "", axis.title = c("Aroma", "Prob. of quality being bad"))
plot_model(model6, type = "pred", terms = "flavor", 
           title = "", axis.title = c("Flavor", "Prob. of quality being bad"))
plot_model(model6, type = "pred", terms = "acidity", 
           title = "", axis.title = c("Acidity", "Prob. of quality being bad"))
```
